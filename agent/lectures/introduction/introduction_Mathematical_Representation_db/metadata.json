{
  "metadata": [
    {
      "block_id": "block_0_0",
      "text": "Ê†áÈ¢ò: Input Space. x ‚àà X is an input vector, also called:. Typically multi-dimensional",
      "full_text": "Ê†áÈ¢ò: Input Space. x ‚àà X is an input vector, also called:. Typically multi-dimensional",
      "page": 0,
      "index": 0
    },
    {
      "block_id": "block_0_1",
      "text": "Ê†áÈ¢ò: Output Space. y ‚àà Y is an output vector, also called:. Typically one-dimensional",
      "full_text": "Ê†áÈ¢ò: Output Space. y ‚àà Y is an output vector, also called:. Typically one-dimensional",
      "page": 0,
      "index": 1
    },
    {
      "block_id": "block_0_2",
      "text": "Ê†áÈ¢ò: Joint Distribution. For supervised learning, we assume that:. where P is a joint distribution on the sample space ùí≥ √ó ùí¥",
      "full_text": "Ê†áÈ¢ò: Joint Distribution. For supervised learning, we assume that:. where P is a joint distribution on the sample space ùí≥ √ó ùí¥",
      "page": 0,
      "index": 2
    },
    {
      "block_id": "block_1_3",
      "text": "Ê†áÈ¢ò: Goal. ÊëòË¶Å: The goal of supervised learning. given x, predict what is y",
      "full_text": "Ê†áÈ¢ò: Goal. ÊëòË¶Å: The goal of supervised learning. given x, predict what is y",
      "page": 1,
      "index": 3
    },
    {
      "block_id": "block_1_4",
      "text": "Ê†áÈ¢ò: Training Dataset. ÊëòË¶Å: Dataset used for training. used to learn an approximation:. or",
      "full_text": "Ê†áÈ¢ò: Training Dataset. ÊëòË¶Å: Dataset used for training. used to learn an approximation:. or",
      "page": 1,
      "index": 4
    },
    {
      "block_id": "block_1_5",
      "text": "Ê†áÈ¢ò: Test Dataset. ÊëòË¶Å: Dataset used for testing. used to make a prediction:. or. to verify prediction accuracy",
      "full_text": "Ê†áÈ¢ò: Test Dataset. ÊëòË¶Å: Dataset used for testing. used to make a prediction:. or. to verify prediction accuracy",
      "page": 1,
      "index": 5
    },
    {
      "block_id": "block_2_6",
      "text": "Ê†áÈ¢ò: Goal. ÊëòË¶Å: The goal of unsupervised learning. In probabilistic settings, find the distribution of x and approximate it. There is no output variable y",
      "full_text": "Ê†áÈ¢ò: Goal. ÊëòË¶Å: The goal of unsupervised learning. In probabilistic settings, find the distribution of x and approximate it. There is no output variable y",
      "page": 2,
      "index": 6
    },
    {
      "block_id": "block_2_7",
      "text": "Ê†áÈ¢ò: Training Dataset. ÊëòË¶Å: Dataset used for training. used to learn an approximation",
      "full_text": "Ê†áÈ¢ò: Training Dataset. ÊëòË¶Å: Dataset used for training. used to learn an approximation",
      "page": 2,
      "index": 7
    },
    {
      "block_id": "block_3_8",
      "text": "Ê†áÈ¢ò: Decision Function Space. or",
      "full_text": "Ê†áÈ¢ò: Decision Function Space. or",
      "page": 3,
      "index": 8
    },
    {
      "block_id": "block_3_9",
      "text": "Ê†áÈ¢ò: Loss Functions. Measure for the 'goodness' of the prediction:",
      "full_text": "Ê†áÈ¢ò: Loss Functions. Measure for the 'goodness' of the prediction:",
      "page": 3,
      "index": 9
    },
    {
      "block_id": "block_3_10",
      "text": "Ê†áÈ¢ò: Risk. Expected loss over the data distribution:",
      "full_text": "Ê†áÈ¢ò: Risk. Expected loss over the data distribution:",
      "page": 3,
      "index": 10
    },
    {
      "block_id": "block_3_11",
      "text": "Ê†áÈ¢ò: Target of Learning. Choose the optimal model that minimizes risk:",
      "full_text": "Ê†áÈ¢ò: Target of Learning. Choose the optimal model that minimizes risk:",
      "page": 3,
      "index": 11
    },
    {
      "block_id": "block_4_12",
      "text": "Ê†áÈ¢ò: Empirical Risk Minimization (ERM). Minimize the average loss over training data:",
      "full_text": "Ê†áÈ¢ò: Empirical Risk Minimization (ERM). Minimize the average loss over training data:",
      "page": 4,
      "index": 12
    },
    {
      "block_id": "block_4_13",
      "text": "Ê†áÈ¢ò: Structural Risk Minimization (SRM). Balances fit and model complexity:",
      "full_text": "Ê†áÈ¢ò: Structural Risk Minimization (SRM). Balances fit and model complexity:",
      "page": 4,
      "index": 13
    },
    {
      "block_id": "block_5_14",
      "text": "Ê†áÈ¢ò: Numerical Optimization Approaches. Computational methods to solve minimization problems:",
      "full_text": "Ê†áÈ¢ò: Numerical Optimization Approaches. Computational methods to solve minimization problems:",
      "page": 5,
      "index": 14
    },
    {
      "block_id": "block_5_15",
      "text": "Ê†áÈ¢ò: Algorithm Selection Criteria",
      "full_text": "Ê†áÈ¢ò: Algorithm Selection Criteria",
      "page": 5,
      "index": 15
    },
    {
      "block_id": "block_6_16",
      "text": "Ê†áÈ¢ò: Training Error",
      "full_text": "Ê†áÈ¢ò: Training Error",
      "page": 6,
      "index": 16
    },
    {
      "block_id": "block_6_17",
      "text": "Ê†áÈ¢ò: Test Error",
      "full_text": "Ê†áÈ¢ò: Test Error",
      "page": 6,
      "index": 17
    },
    {
      "block_id": "block_7_18",
      "text": "Ê†áÈ¢ò: Generalization Error",
      "full_text": "Ê†áÈ¢ò: Generalization Error",
      "page": 7,
      "index": 18
    },
    {
      "block_id": "block_7_19",
      "text": "Ê†áÈ¢ò: Bias-Variance Tradeoff",
      "full_text": "Ê†áÈ¢ò: Bias-Variance Tradeoff",
      "page": 7,
      "index": 19
    },
    {
      "block_id": "block_8_20",
      "text": "Ê†áÈ¢ò: What is Overfitting?. Occurs when a model:",
      "full_text": "Ê†áÈ¢ò: What is Overfitting?. Occurs when a model:",
      "page": 8,
      "index": 20
    },
    {
      "block_id": "block_8_21",
      "text": "Ê†áÈ¢ò: Symptoms of Overfitting",
      "full_text": "Ê†áÈ¢ò: Symptoms of Overfitting",
      "page": 8,
      "index": 21
    },
    {
      "block_id": "block_8_22",
      "text": "Ê†áÈ¢ò: Visual Representation",
      "full_text": "Ê†áÈ¢ò: Visual Representation",
      "page": 8,
      "index": 22
    },
    {
      "block_id": "block_9_23",
      "text": "Ê†áÈ¢ò: Regularization. Technique to prevent overfitting by adding complexity penalty:",
      "full_text": "Ê†áÈ¢ò: Regularization. Technique to prevent overfitting by adding complexity penalty:",
      "page": 9,
      "index": 23
    },
    {
      "block_id": "block_9_24",
      "text": "Ê†áÈ¢ò: Cross-Validation (CV). Procedure for robust model selection and hyperparameter tuning:",
      "full_text": "Ê†áÈ¢ò: Cross-Validation (CV). Procedure for robust model selection and hyperparameter tuning:",
      "page": 9,
      "index": 24
    },
    {
      "block_id": "block_9_25",
      "text": "Ê†áÈ¢ò: Hyperparameter Optimization. Strategies for tuning hyperparameters:",
      "full_text": "Ê†áÈ¢ò: Hyperparameter Optimization. Strategies for tuning hyperparameters:",
      "page": 9,
      "index": 25
    }
  ],
  "vector_dim": 768
}